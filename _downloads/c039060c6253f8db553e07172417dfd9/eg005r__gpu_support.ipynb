{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Evaluating CPU vs. GPU Performance\n\nGPU Support has been added to mutiple classes in WhoBPyT. This code is for evaluating the difference in speed between CPU and GPU. The relative performance will depend on the hardware being used. \n\nThis code is set to run on CPU by default, and then GPU can be tested by updating the device (See Importage Section).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importage\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# whobpyt stuff\nimport whobpyt\nfrom whobpyt.datatypes import par, Recording\nfrom whobpyt.models.RWWEI2 import RWWEI2_EEG_BOLD, RWWEI2_EEG_BOLD_np, RWWEI2, RWWEI2_np, ParamsRWWEI2\nfrom whobpyt.models.BOLD import BOLD_Layer, BOLD_np, BOLD_Params\nfrom whobpyt.models.EEG import EEG_Layer, EEG_np, EEG_Params\nfrom whobpyt.optimization import CostsFC, CostsPSD, CostsMean, CostsFixedFC, CostsFixedPSD\nfrom whobpyt.optimization.custom_cost_mmRWW2 import CostsmmRWWEI2\nfrom whobpyt.run import Model_fitting, Fitting_FNGFPG, Fitting_Batch\nfrom whobpyt.data.generators import gen_cube\n\n# general python stuff\nimport time\nimport torch\nimport numpy as np\nimport pandas as pd\n\n# viz stuff\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nprint(\"Is cuda avaliable?\")\nprint(torch.cuda.is_available())\n\ndevice = torch.device(\"cpu\") #Options: \"cpu\" or \"cuda\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining the Data and Parameters\n---------------------------------------------------- \n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the Synthetic Cube Data For Demo Purposes\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "syntheticCubeInfo = gen_cube(device)\nnum_regions = 8\nnum_channels = 6\n\nCon_Mtx = syntheticCubeInfo[\"SC\"]\ndist_mtx = syntheticCubeInfo[\"dist\"]\nLF_Norm = syntheticCubeInfo[\"LF\"]\nsourceFC = syntheticCubeInfo[\"Source FC\"]\nchannelFC = syntheticCubeInfo[\"Channel FC\"]\n\nprint(max(abs(torch.linalg.eig(Con_Mtx).eigenvalues)))\nmask = np.eye(num_regions)\nsns.heatmap(Con_Mtx.to(torch.device(\"cpu\")), mask = mask, center=0, cmap='RdBu_r', vmin=-0.1, vmax = 0.25)\nplt.title(\"SC of Artificial Data\")\n\n# Create a RWW Params\nparamsNode = ParamsRWWEI2(num_regions)\n\nparamsNode.J = par((0.15 * np.ones(num_regions)), fit_par = True, asLog = True) #This is a parameter that will be updated during training\nparamsNode.G = par(torch.tensor(1.0), None, None, True, False, False)\nparamsNode.sig = par(torch.tensor(0.01), None, None, True, False, False)\nparamsNode.to(device)\n\n#Create #EEG Params\nparamsEEG = EEG_Params(torch.eye(num_regions))\nparamsEEG.LF = LF_Norm.to(device)\nparamsEEG.to(device)\n\n#Create BOLD Params\nparamsBOLD = BOLD_Params()\nparamsBOLD.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training a CNMM Model - Fixed PSD with Batched Paradigm\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Simulation Length\nstep_size = 0.1 # Step Size in msecs\nsim_len = 1500 # Simulation length in msecs\nmodel = RWWEI2(num_regions, paramsNode, Con_Mtx, dist_mtx, step_size, sim_len, device = device)\n\ndemoPSD = torch.rand(100).to(device)\nobjFun = CostsFixedPSD(num_regions = num_regions, simKey = \"E\", sampleFreqHz = 10000, minFreq = 1, maxFreq = 100, targetValue = demoPSD, rmTransient = 5000, device = device)\n\nempSubject = {}\nnum_epochs = 2\nnum_recordings = 1\nbatch_size = 50\n\n# Create a Fitting Object\nF = Fitting_Batch(model, objFun, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "model training\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\nF.train(stim = 0, empDatas = [empSubject], num_epochs = num_epochs, batch_size = batch_size, learningrate = 0.05, staticIC = False)\nend_time = time.time()\nprint(str((end_time - start_time)/60) + \" minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plots of loss over Training\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(1,len(F.trainingStats.loss)+1), F.trainingStats.loss)\nplt.title(\"Total Loss over Training Epochs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training a CNMM Model - Multimodal Objective with FNG-FPG Paradigm\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Simulation Length\nstep_size = 0.1 # Step Size in msecs\nsim_len = 5000 # Simulation length in msecs\nmodel = RWWEI2_EEG_BOLD(num_regions, num_channels, model.params, paramsEEG, paramsBOLD, Con_Mtx, dist_mtx, step_size, sim_len, device)\n\ntargetValue = torch.tensor([0.164]).to(device)\nobjFun = CostsmmRWWEI2(num_regions, simKey = \"E\", targetValue = targetValue, device = device)\n\n# Create a Fitting Object\nF = Fitting_FNGFPG(model, objFun, device)\n\n# Training Data\nempSubject = {}\nempSubject['EEG_FC'] = channelFC\nempSubject['BOLD_FC'] = sourceFC\nnum_epochs = 3\nnum_recordings = 1\nblock_len = 100 # in msec\n\n# model training\nstart_time = time.time()\nF.train(stim = 0, empDatas = [empSubject], num_epochs = num_epochs, block_len = block_len, learningrate = 0.05, resetIC = False)\nend_time = time.time()\nprint(str((end_time - start_time)/60) + \" minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plots of loss over Training\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(1,len(F.trainingStats.loss)+1), F.trainingStats.loss)\nplt.title(\"Total Loss over Training Epochs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CNMM Verification Model\n\nThe Multi-Modal Model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.eeg.params.LF = model.eeg.params.LF.cpu()\n\nval_sim_len = 20*1000 # Simulation length in msecs\nmodel_validate = RWWEI2_EEG_BOLD_np(num_regions, num_channels, model.params, model.eeg.params, model.bold.params, Con_Mtx.detach().cpu().numpy(), dist_mtx.detach().cpu().numpy(), step_size, val_sim_len)\n\nsim_vals, hE = model_validate.forward(external = 0, hx = model_validate.createIC(ver = 0), hE = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plots of S_E and S_I Verification\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (16, 8))\nplt.title(\"S_E and S_I\")\nfor n in range(num_regions):\n    plt.plot(sim_vals['E'][0:10000, n], label = \"S_E Node = \" + str(n))\n    plt.plot(sim_vals['I'][0:10000, n], label = \"S_I Node = \" + str(n))\n\nplt.xlabel('Time Steps (multiply by step_size to get msec), step_size = ' + str(step_size))\nplt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plots of EEG PSD Verification\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampleFreqHz = 1000*(1/step_size)\nsdAxis, sdValues = CostsPSD.calcPSD(torch.tensor(sim_vals['eeg']), sampleFreqHz, minFreq = 2, maxFreq = 40)\nsdAxis_dS, sdValues_dS = CostsPSD.downSmoothPSD(sdAxis, sdValues, 32)\nsdAxis_dS, sdValues_dS_scaled = CostsPSD.scalePSD(sdAxis_dS, sdValues_dS)\n\nplt.figure()\nfor n in range(num_channels):\n    plt.plot(sdAxis_dS, sdValues_dS_scaled.detach()[:,n])\nplt.xlabel('Hz')\nplt.ylabel('PSD')\nplt.title(\"Simulated EEG PSD: After Training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plots of BOLD FC Verification\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "skip_trans = int(500/step_size)\nsim_FC = np.corrcoef((sim_vals['bold'].T)[:,skip_trans:])\n\nplt.figure(figsize = (8, 8))\nplt.title(\"Simulated BOLD FC: After Training\")\nmask = np.eye(num_regions)\nsns.heatmap(sim_FC, mask = mask, center=0, cmap='RdBu_r', vmin=-1.0, vmax = 1.0)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}