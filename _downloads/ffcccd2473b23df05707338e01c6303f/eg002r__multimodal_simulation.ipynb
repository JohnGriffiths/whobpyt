{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Fitting S_E Mean to 0.164 using default RWW Parameters\n\nWhat is being modeled:\n\n- Created a Sphere'd Cube (chosen points on cube projected onto radius = 1 sphere), so that regions were more evently distributed. All corners of cube chosen as regions, thus there are 8 regions. \n\n- EEG channels located on the center of each face of the cube. Thus there are 6 EEG channels.\n\n- Added some randomness to initial values - to decorrelate the signals a bit. Looking for FC matrix to look similar to SC matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importage\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# whobpyt stuff\nfrom whobpyt.depr.models import RNNJANSEN,ParamsJR,RNNWWD,RWW_Layer,RWW_Params,BOLD_Layer,BOLD_Params,EEG_Layer,EEG_Params,Jansen_Layer\nfrom whobpyt.depr.objective import meanVariableLoss,powerSpectrumLoss,functionalConnectivityLoss\nfrom whobpyt.depr.fit import Model_fitting\n\n# general python stuff\nimport torch, numpy as np, pandas as pd\n\n# viz stuff\nimport seaborn as sns, matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining Model Parameters\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_regions = 8\nnum_channels = 6\n\n# Simulation Length\nstep_size = 0.1 # Step Size in msecs\nsim_len = 2000 # Simulation length in msecs\n\nskip_trans = int(500/step_size)\n\n# Initial Conditions\nS_E = 0.6; S_I = 0.1; x = 0.0000; f = 2.4286; v = 1.3283; q = 0.6144 # x,f,v,q might be choosen for different initial S_E\ninit_state = torch.tensor([[S_E, S_I, x, f, v, q]]).repeat(num_regions, 1)\n\n# Add randomness\ninit_state = init_state + torch.randn_like(init_state)/30 # Randomizing initial values\n\n# Create a RWW Params\nparamsNode = RWW_Params(num_regions)\n\n#Create #EEG Params\nparamsEEG = EEG_Params(torch.eye(num_regions))\n\n#Create BOLD Params\nparamsBOLD = BOLD_Params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Further Adjusting Parameters for Network\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "paramsNode.J = torch.nn.Parameter(0.15  * torch.ones(num_regions)) #This is a parameter that will be updated during training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating a physically possible (in 3D Space) Structural Connectivity Matrix\n\nFirst, get corner points on a cube and project onto a sphere\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "square_points = torch.tensor([[1.,1.,1.],\n                              [-1.,1.,1.],\n                              [1.,-1.,1.],\n                              [-1.,-1.,1.],\n                              [1.,1.,-1.],\n                              [-1.,1.,-1.],\n                              [1.,-1.,-1.],\n                              [-1.,-1.,-1.]])\nsphere_points = square_points / torch.sqrt(torch.sum(torch.square(square_points), axis = 1)).repeat(3, 1).t()\n\n# Second, find the distance between all pairs of points\ndist_mtx = torch.zeros(num_regions, num_regions)\nfor x in range(num_regions):\n    for y in range(num_regions):\n        dist_mtx[x,y]= torch.linalg.norm(sphere_points[x,:] - sphere_points[y,:])\n\n# Third, Structural Connectivity defined to be 1/dist and remove self-connection values\nSC_mtx = 1/dist_mtx\nfor z in range(num_regions):\n    SC_mtx[z,z] = 0.0\n\n# Fourth, Normalize the matrix\nSC_mtx_norm = (1/torch.linalg.matrix_norm(SC_mtx, ord = 2)) * SC_mtx\nCon_Mtx = SC_mtx_norm\n\n\n# Blah\n\nprint(max(abs(torch.linalg.eig(SC_mtx_norm).eigenvalues)))\nmask = np.eye(num_regions)\nsns.heatmap(Con_Mtx, mask = mask, center=0, cmap='RdBu_r', vmin=-0.1, vmax = 0.25)\nplt.title(\"SC of Artificial Data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating a Lead Field Matrix\n\nPlacing an EEG Electrode in the middle of each cube face. \nThen electrode is equally distance from four courner on cube face squre.\nAssume no signal from further four points. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Lead_Field = torch.tensor([[1,1,0,0,1,1,0,0],\n                           [1,1,1,1,0,0,0,0],\n                           [0,1,0,1,0,1,0,1],\n                           [0,0,0,0,1,1,1,1],\n                           [1,0,1,0,1,0,1,0],\n                           [0,0,1,1,0,0,1,1]], dtype = torch.float)\nLF_Norm = (1/torch.linalg.matrix_norm(Lead_Field, ord = 2)) * Lead_Field\n\nparamsEEG.LF = LF_Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating a \"Connectivity Matrix\" for Channel Space\n\nGenerating a physically possible (in 3D Space) \"Channel\" Connectivity Matrix\nThat is a theoretical matrix for the EEG SC to be fit to\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# First, get face points on a cube and project onto a sphere\nLF_square_points = torch.tensor([[0.,1.,0.],\n                                 [0.,0.,1.],\n                                 [-1.,0.,0.],\n                                 [0.,0.,-1.],\n                                 [1.,0.,0.],\n                                 [0.,-1.,0.]])\n# Note: this does nothing as the points are already on the r=1 sphere\nLF_sphere_points = LF_square_points / torch.sqrt(torch.sum(torch.square(LF_square_points), axis = 1)).repeat(3, 1).t()\n\n\n# Second, find the distance between all pairs of channel points\nLF_dist_mtx = torch.zeros(num_channels, num_channels)\nfor x in range(num_channels):\n    for y in range(num_channels):\n        LF_dist_mtx[x,y]= torch.linalg.norm(LF_sphere_points[x,:] - LF_sphere_points[y,:])\n\n# Third, Structural Connectivity defined to be 1/dist and remove self-connection values\nLF_SC_mtx = 1/LF_dist_mtx\nfor z in range(num_channels):\n    LF_SC_mtx[z,z] = 0.0\n\n# Fourth, Normalize the matrix\nLF_SC_mtx_norm = (1/torch.linalg.matrix_norm(LF_SC_mtx, ord = 2)) * LF_SC_mtx\nLF_Con_Mtx = LF_SC_mtx_norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the CNMM Model\n\nThe Multi-Modal Model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class mmModel(torch.nn.Module):\n    def __init__(self):\n        super(mmModel, self).__init__()\n        \n        self.nodes = RWW_Layer(num_regions, paramsNode, Con_Mtx, dist_mtx, step_size)\n        self.eeg = EEG_Layer(num_regions, paramsEEG, num_channels)\n        self.bold = BOLD_Layer(num_regions, paramsBOLD)\n        \n        self.next_start_state = init_state\n        \n    def forward(self, debug = False):\n        \n        self.step_size = step_size #in msec\n        self.sim_len = sim_len #in msec\n        \n        node_states, node_history = self.nodes.forward(self.next_start_state[:, 0:2], self.sim_len, debug = debug)\n        EEG_history = self.eeg.forward(self.step_size, self.sim_len, node_history)\n        BOLD_states, BOLD_history = self.bold.forward(self.next_start_state[:, 2:6], self.step_size, self.sim_len, node_history[:,:,0])\n\n        self.next_start_state = torch.cat((node_states, BOLD_states), dim=1).detach()\n        \n        return node_history, EEG_history, BOLD_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the Objective Function\n\nWritten in such as way as to be able to adjust the relative importance of components that make up the objective function.\nAlso, written in such a way as to be able to track and plot indiviual components losses over time. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class objectiveFunction():\n    def __init__(self):\n        # Weights of Objective Function Components\n        self.S_E_mean_weight = 1\n        self.S_I_mean_weight = 0 # Not Currently Used\n        self.EEG_PSD_weight = 0 # Not Currently Used\n        self.EEG_FC_weight = 0 # Not Currently Used\n        self.BOLD_PSD_weight = 0 # Not Currently Used\n        self.BOLD_FC_weight = 0 # Not Currently Used\n        \n        # Functions of the various Objective Function Components\n        self.S_E_mean = meanVariableLoss(num_regions, varIdx = 0, targetValue = torch.tensor([0.164]))\n        #self.S_I_mean = meanVariableLoss(...) # Not Currently Used\n        #self.EEG_PSD = powerSpectrumLoss(num_channels, varIdx = 0, sampleFreqHz = 1000*(1/step_size), targetValue = targetEEG)\n        #self.EEG_FC = functionalConnectivityLoss(...) # Not Currently Used\n        #self.BOLD_PSD = powerSpectrumLoss(...) # Not Currently Used\n        #self.BOLD_FC = functionalConnectivityLoss(num_regions, varIdx = 4, targetValue = SC_mtx_norm)\n                \n    def calcTotalLoss(self, node_history, EEG_history, BOLD_history, returnLossComponents = False):\n        \n        S_E_mean_loss = self.S_E_mean.calcLoss(node_history) \n        S_I_mean_loss = torch.tensor([0]) #self.S_I_mean.calcLoss(node_history)\n        EEG_PSD_loss = torch.tensor([0]) #self.EEG_PSD.calcLoss(EEG_history) \n        EEG_FC_loss = torch.tensor([0]) #self.EEG_FC.calcLoss(EEG_history)\n        BOLD_PSD_loss = torch.tensor([0]) #self.BOLD_PS.calcLoss(BOLD_history)\n        BOLD_FC_loss = torch.tensor([0]) #self.BOLD_FC.calcLoss(BOLD_history)\n                \n        totalLoss = self.S_E_mean_weight*S_E_mean_loss + self.S_I_mean_weight*S_I_mean_loss \\\n                  + self.EEG_PSD_weight*EEG_PSD_loss   + self.EEG_FC_weight*EEG_FC_loss \\\n                  + self.BOLD_PSD_weight*BOLD_PSD_loss + self.BOLD_FC_weight*BOLD_FC_loss\n                 \n        if returnLossComponents:\n            return totalLoss, (S_E_mean_loss.item(), S_I_mean_loss.item(), EEG_PSD_loss.item(), EEG_FC_loss.item(), BOLD_PSD_loss.item(), BOLD_FC_loss.item())\n        else:\n            return totalLoss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training The Model\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = mmModel()\nTotalLossFn = objectiveFunction()\n\n\n#\n\nprint(list(model.named_parameters()))\n\n\n#\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n\n\n#\n\nLossComp = list()\n\nJ_values = list()\n\nepochs = 20\n\nfor i in range(epochs):\n    print(i)\n    \n    node_history, EEG_history, BOLD_history = model.forward()\n    totalLoss, lossComponents = TotalLossFn.calcTotalLoss(node_history[skip_trans:,:,:], EEG_history[skip_trans:,:,:], BOLD_history[skip_trans:,:,:], returnLossComponents = True)\n    print(\"totalLoss = \", totalLoss.item())\n    \n    optimizer.zero_grad()\n    totalLoss.backward()\n    optimizer.step()\n    \n    LossComp.append(lossComponents)\n    J_values.append(model.nodes.J.detach().clone().numpy())\n\n    \n    print(\"J values = \", model.nodes.J.detach().clone().numpy())\n\n\n# \n\nplt.plot(LossComp)\nplt.title(\"Total Loss over Training Epochs\")\n\n\n# \n\nplt.plot(J_values)\nplt.title(\"J_{i} Values Changing Over Training Epochs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots of S_E and S_I After Training\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (16, 8))\nplt.title(\"S_E and S_I\")\nfor n in range(num_regions):\n    plt.plot(node_history.detach()[:,n,0], label = \"S_E Node = \" + str(n))\n    plt.plot(node_history.detach()[:,n,1], label = \"S_I Node = \" + str(n))\n\nplt.xlabel('Time Steps (multiply by step_size to get msec), step_size = ' + str(step_size))\nplt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots of EEG PSD\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampleFreqHz = 1000*(1/step_size)\nsdAxis, sdValues = powerSpectrumLoss.calcPSD(EEG_history[skip_trans:,:,0], sampleFreqHz, minFreq = 2, maxFreq = 40)\nsdAxis_dS, sdValues_dS = powerSpectrumLoss.downSmoothPSD(sdAxis, sdValues, 32)\nsdAxis_dS, sdValues_dS_scaled = powerSpectrumLoss.scalePSD(sdAxis_dS, sdValues_dS)\n\nplt.figure()\nplt.plot(sdAxis_dS, sdValues_dS_scaled.detach())\nplt.xlabel('Hz')\nplt.ylabel('PSD')\nplt.title(\"Simulated EEG PSD: After Training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots of BOLD FC\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(BOLD_history[skip_trans:, :, 4].shape)\nsim_FC = functionalConnectivityLoss.calcFC(BOLD_history[:, :, 4]).detach()\n\nplt.figure(figsize = (8, 8))\nplt.title(\"Simulated BOLD FC: After Training\")\nmask = np.eye(num_regions)\nsns.heatmap(sim_FC, mask = mask, center=0, cmap='RdBu_r', vmin=-1.0, vmax = 1.0)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}